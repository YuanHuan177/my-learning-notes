# 损失函数总结

## 对数似然函数

在逻辑斯蒂回归模型中使用对数似然函数估计模型参数，假设 $$P(Y=1|x)=\pi(x)$$，$$P(Y=0|x)=1-\pi(x)$$，似然函数为：

$$\prod_{i=1}^N[\pi(x_i)]^{y_i}[1-\pi(x_i)]^{1-y_i}$$

对数似然函数为：

$$L(w)=\sum_{i=1}^N[y_ilog\pi(x_i) + (1-y_i)log(1-\pi(x_i))]$$

$$=\sum_{i=1}^N[y_i(w.x_i) - log(1+exp(w.x_i))]$$

也就是$$-\frac{1}{N} \sum _{i=1}^N(y_i*log (t_i) + (1-y_i)*log(1-t_i))$$，这种写法只当标签 $$y \in \{0,1\}$$ 时成立；当标签为$$y \in \{-1,1\}$$ 时，对数损失函数应该写成 $$-\frac{1}{N} \sum _{i=1}^N log(1+exp(-y_i*t_i))$$

## softamx cross entropy loss

在多分类任务中，经常使用 softamx 交叉熵损失函数，当任务为二分类是，退化为 logloss 对数损失函数。

$$E(t,y)=−\sum _jt_jlog y_j$$

其中，t 和 y 分别表示神经网络的目标标签和和神经网络的类别概率输出，对于多分类，我们的类别概率是使用 softmax 进行归一化的：

$$y_j=softmax(z_j)= \frac{e^{zj}}{\sum_j e^{zj}}$$

这个公式需要输入没有经过缩放变换的logits，还有就是使用本目标损失函数的时候不要在网络的最后一层使用 softmax 层或者激活函数，会导致结果不正确。

## Categorical Crossentropy

交叉熵损失函数是也是常用的一种损失函数，它表示预测值y与目标值t之间的距离。主要应用在互相排斥的分类任务中，公式为： 

$$H(y,t)=H_t(y)=−\sum _it_i log y_i$$

## Binary Crossentropy

这个损失函数主要是用来计算预测值y与目标值t之间的 sigmoid 交叉熵，主要用来多分类任务中，但是这个分类任务不是互斥的，和上面的损失函数不同，这个对同一个输入可以输出多个标签。公式为： 

$$y−y∗t+log(1+exp(−y))$$

为了防止溢出，我们进行如下变换： 

$$ max(y,0)−y∗t+log(1+exp(−abs(y)))$$

## Weighted Crossentropy

主要用来计算神经元之间的权值的交叉熵损失函数，t表示目标标签，y表示输入的预测值。该损失函数和上一个损失函数很像，唯一一点不同的就是：

该损失函数允许对负误差或者正误差加权 来调整precision 和recall

一般的交叉损失函数为： 

$$t∗−log(sigmoid(y))+(1−t)∗−log(1−sigmoid(y))$$

当我们乘上 pos_weight 之后的公式就变成：
 
$$t∗−log(sigmoid(y))∗pos\_weight+(1−t)∗−log(1−sigmoid(y))$$

为了避免溢出，我们将公式变为：

$$(1−t)∗y+l∗(log(1+exp(−abs(y)))+max(−y,0))$$

其中，l 表示： 

$$l=(1+(pos\_weight−1)∗t)$$

## Mean Square Loss

这个损失函数就很常见了，t 表示目标值，y 表示预测值输出。公式为： 

$$MSE=\frac{1}{n} \sum_{i=1}^n(y_i−t_i)^2$$

## Hinge Loss

在支持向量机中，模型的分离平面 $$w^*.x + b = 0$$，决策函数为 $$f(x)=sign(w^*.x + b)$$，目标函数如下：

$$\sum_{i=1}^n[1-y_i(w^*.x_i + b)]_+ + \lambda ||w||^2$$

使用的是合页损失函数，这个也是很常见的一个loss函数， t 表示目标值，y 表示预测值输出。公式为： 

$$\partial (y)=max(0, 1−t∗y)$$

当实例点$$(x_i,y_i)$$被分类正确时，损失是 0，否则损失是 $$1-y_i(w^*.x_i + b)$$

## Contrastive Loss

对比损失函数。这个损失函数主要用在Siamese network中，参见论文 [链接](http://yann.lecun.com/exdb/publis/pdf/chopra-05.pdf)。d 表示目标值，y 表示预测值输出。 

$$L=\frac{1}{2N}\sum _{n=1}^Nyd^2+(1−y)max(margin−d,0)^2$$

其中 d 表示两个样本特征的欧氏距离 

$$d=||x_i−x_j||^2$$