# 数据挖掘竞赛操作指南 -- 结构化数据篇

结构化的数据是指可以使用关系型数据库表示和存储，表现为二维形式的数据。一般特点是：数据以行为单位，一行数据表示一个实体的信息，每一行数据的属性是相同的。举一个例子：

```
id      name    age     gender
1       lyh     12      male
2       liangyh 13      female
3       liang   18      male
```
各个平台举办的数据挖掘类竞赛中，大部分都是结构化数据，特别是早期；近年来随着自然语言处理和计算机视觉的兴起，非结构化数据类型的数据挖掘竞赛也越来越多。针对结构化数据挖掘竞赛，这里总结一下基本的竞赛操作指南。

## 1、数据探索分析

拿到数据，我们首先需要做的是对数据进行探索分析，从整体了解数据，把握数据。

### 分布分析

1. 定量数据：频率分析、频率分布表、直方图、茎叶图
2. 定性数据：饼图、条形图

### ①特征变量分析

分析*变量之间两两的分布和相关度*，可以用于发现高相关和共线性的特征。我们可以看看数据中各个特征的协方差矩阵和相似度矩阵：

```python
data_df.cov()
data_df.corr()
```

协方差的值接近于 0 表明两个变量不具有（线性）关系。对于**数据探索，相关性比协方差更可取**。相关矩阵 R 的第 ij 个元素是数据的第 i 个和第 j 个属性之间的相关性。

$$r_{ij} = correlation(x_i,x_j)= covariance(x_i,x_j)/s_is_j$$

其中 $$s_i$$ 和 $$s_j$$ 分别是 $$x_i,x_j$$ 的方差。

线性相关性指标：

- $$|r|<=0.3$$ 为不存在线性相关
- $$0.3<|r|<=0.5$$ 为低度线性相关
- $$0.5<|r|<=0.8$$ 为显著线性相关
- $$|r|> 0.8$$ 为高度线性相关

### ②目标变量的分布

- 目标变量为连续值（回归）：查看其值域范围是否较大，如果较大，可以考虑对其进行对数变换，并以变换后的值作为新的目标变量进行建模（在这种情况下，需要对预测结果进行逆变换）。一般情况下，可以对连续变量进行Box-Cox变换。通过变换可以使得模型更好的优化，通常也会带来效果上的提升。
- 目标变量为离散值（分类）：如果数据分布不平衡，考虑是否需要上采样/下采样；如果目标变量在某个ID上面分布不平衡，在划分本地训练集和验证集的时候，需要考虑分层采样（Stratified Sampling）

### 统计量分析

用统计学指标对定量数据进行描述性分析，例如均值，中位数，众数；极差，标准差，四分位数间距等。

散布度量：极差和方差，这种度量表明属性值是否散布很宽，或者是否相对集中在单个点（如均值）附近。

给定一个属性x，它具有 m 个值 $${x1,x2,...,xm}$$，x 的极差定义为：$$range(x)=max(x)-min(x)$$。尽管极差标识最大散布，但是如果大部分值都集中在一个较小的范围内，并且更极端的值的个数相对较少，则可能会引起误解。因此，**作为散布的度量，方差和标准差更可取**。

使用 DataFrame 进行统计分析，如果是分类任务，我们可以看看每个类别下各个特征的分布有没有区别。

```python
data_df[data_df['target']==0].describe()
data_df[data_df['target']==1].describe()
data_df[data_df['target']==2].describe()
```

### 缺失值分析

缺失值产生的原因：

1. 有些信息暂时无法获取，或者获取信息的代价太大。
2. 有些信息是被遗漏的。可能是因为输入时认为不重要、忘记填写或对数据理解错误等一些人为因素而遗漏，也可能是由于数据采集设备的故障、存储介质的故障、传输媒体的故障等非人为原因而丢失。
3. 属性值不存在。在某些情况下，缺失值并不意味着数据有错误。对一些对象来说某些属性值是不存在的，如一个未婚者的配偶姓名、一个儿童的固定收入等。

### 异常值分析

异常可能由于测量、输入错误或系统运行错误而造成，也可能是由数据内在特性引起的，或异常行为所导致。异常值分析是检验数据是否含有不合理的数据。由于异常产生的机制是不确定的，因此，异常检测算法检测出的“异常”是否真正地对应为实际的异常行为，不是由异常检测算法来说明、解释的，只能由领域专家来解释。

**异常值分析常用方法：**

1. 描述性统计分析
2. Z得分
3. 箱形图分析

### 可视化

为了总体的，更直观的观察数据的分布，我们可以使用可视化技术来分析数据。常用的工具有：<font color=red>`matplotlib，seaborn`</font> 。

一些基本绘图操作：

1. <font color=red>单变量</font>

直方图：`plt.hist(x, bins=10)`。

Kdeplot：`sns.kdeplot(x,shade=True)`。

Distplot：`sns.distplot(x, bins=20, kde=False, rug=True)`，通过观察bin来对数据进行切分并做one-hot编码形成新的特征。

2. <font color=red>双变量</font>

Scatterplot：`plt.scatter(df['x'].values,df['y'].values)`，当数据比较多的时候,建议采样观察,不然真的很耗时.通过Scatterplot我们可以很容易的发现一些数据的分布规律,是否有簇的存在等等,在涉及类似于经纬度的问题时,我们经常会通过scatterplot看数据,然后考虑聚类等操作.

Jointplot：`sns.jointplot(x="x", y="y", data=df)`；Hexbin绘图和KDE绘图,这两个绘图大致可以更加<font color=red>直观的炫酷的</font>看出数据的一个分布情况(例如hex图,越白的地方数据就越少,基本都没有数据在那里)。`sns.jointplot(x="x", y="y", data=df,kind ='hex' )`

![avater](./pic/Jointplot.png)

pairplot: 该函数会同时绘制数据中所有特征两两之间的关系图.因为pairplot是建立在pairgrid之上,所以可以将中间的很多函数进行变换,例如下面的kde的例子.

```
iris = sns.load_dataset("iris")
sns.pairplot(iris);
```

![avater](./pic/pairplot.png)

</font size=6>对于分类数据</font>而言，由于我们可以用颜色或者标记去区别不同的类，所以我们的坐标轴可以全部用于属性的表示，比如说在这里我们可以用一个二维图来表示每个样本对应的两个属性的分布

```python
from matplotlib import pyplot as plt
plt.plot(data_df[data_df['target']==0]['petal length (cm)'],data_df[data_df['target']==0]['petal width (cm)'],'r*',label='0')
plt.plot(data_df[data_df['target']==1]['petal length (cm)'],data_df[data_df['target']==1]['petal width (cm)'],'ro',label='1')
plt.plot(data_df[data_df['target']==2]['petal length (cm)'],data_df[data_df['target']==2]['petal width (cm)'],'bx',label='2')
plt.xlabel('petal length (cm)')
plt.ylabel('petal width (cm)')
plt.legend(loc='best')
plt.grid()
plt.show()
```

![avater](./pic/dmkehishua1.png)

使用直方图可以观察并比较每个类别的各项属性的分布，通过箱形图我们则可以比较不同类别的各项属性的分布及集中程度。

```python
from matplotlib import pyplot as plt
plt.hist(data_df[data_df['target']==0]['petal length (cm)'],color='blue',label='Class 0',alpha=0.5,bins=20)
plt.hist(data_df[data_df['target']==1]['petal length (cm)'],color='red',label='Class 1',alpha=0.5,bins=20)
plt.hist(data_df[data_df['target']==2]['petal length (cm)'],color='green',label='Class 2',alpha=0.5,bins=20)
plt.legend(loc='best')
plt.grid()
plt.show()
data_df.boxplot(by='target',layout=(2,2))
plt.show()
```

![avater](./pic/dmkehishua2.png)
![avater](./pic/dmkehishua3.png)

使用热力图分析各个特征的相关性：


### <font color=red>时间序列数据分析</font>

- 绘图查看时序是否出现断层，中间是有一段时间没有记录；序列是否存在较大的波动，是否存在冲突。
- 序列是否存在周期性，序列最近变现出什么趋势。

时间序列的几大模式：

- 趋势：明显的长期增长或下降（线性或者震荡）
- 季节性：如年份、每周、季节性
- 循环性：指数据不以固定的频率展现出上升以及下降趋势

<font color=red>**自相关性**</font>

在时间序列里存在一些自相关稀疏，例如 r1 可以用来评估 y1 和 y2 之间的关系，计算公式如下：

$$r_k = \frac{\sum_{t=k+1}^T (y_t-\overline y)(y_{t-k}-\overline y)}{\sum_{t=1}^T (y_t-\overline y)^2}$$

T 为时间序列长度。

![avater](./pic/times.png)

从上图可以看到：

1. r4相对比较大，可能是因为周期为4的原因
2. r2 相对较小，可能是因为周期为 4 ，而 2 恰好在峰值之后的中间
3. 蓝色的虚线表示相关性是否和 0 严格不同

季节性和趋势给自相关带来的影响：

1. 当数据是季节性的（周期性），自相关稀疏会在季节性的位置（lag = k,2k,3k,..）获得较大的值；如果我们的时间序列以 k 为周期的话，那么我们的 rk 会较大；
2. 当数据存在趋势，则对于小的 lag（如1，2）的自相关系数就会变得较大，但是当把 lag 设置大一点的时候，就会得到缓解。

<font color=red>**白噪音**</font>

当时间序列没有显示自相关性是，我们称这种时间序列为白噪音。

![avater](./pic/whitenoise.png)

## 2、数据清洗

数据清洗工作包括数据转换、数据离散化、数据缺失替换和数据异常点处理等。

### 数据转换

1. 光滑：
2. 聚集：
3. 数据泛化：
4. 规范化：
5. 属性构造：

数据去重` pd.drop_duplicates()`

### 特征缺失值的处理

- 特征值为连续值：按不同的分布类型对缺失值进行补全：偏正态分布，使用均值代替，可以保持数据的均值；偏长尾分布，使用中值代替，避免受 outlier 的影响；
- 特征值为离散值：使用众数代替。

另外可以对只有少数缺失值的特征进行插值填充，或者使用贝叶斯公式、回归、决策树推断出缺失的数据（最常用）。缺点是，数据可能并不正确。

### 异常样本的处理

异常数据容易对数据集造成噪声，对于噪声数据，我们可以：

1. 分箱：箱均值平滑、箱中值平滑、箱边界平滑；应用场景：噪声数据不能删除，使用其他数据替换噪声数据
2. 聚类：应用场景：找出离群点（去除数据）

## 3、数据集划分

## 3、特征工程

特征工程依赖于前面的数据探索分析，也依赖于专业业务知识。

### ①连续值特征

- 如果为长尾分布并且考虑使用线性模型，可以对变量进行幂变换或者对数变换。
- 离散化，这样让特征更加鲁棒性。
- 特征之间进行“加减乘除”之类的特征组合。

### ②离散值 ID 类特征

- 观察每个离散值的频率分布，对于频次较低的特征，可以考虑统一编码为“其他”类别。
- 对于单值离散特征，可以考虑 one-hot 编码，`LabelEncoder，OneHotEncoder`。
- 对于多值离散特征可以考虑使用 bag-of-word，或者采用嵌入式词向量，比如一个有先后行为顺序的点击流特征，我们可以将特征按照时间先后顺序排序，然后进行词向量训练得到 embedding 表达，最后使用所以特征取值的 embedding 平均值做特征。
- 对于单值离散特征可以将其进行两两或者多个之间组合，进行组合特征的交叉统计转化率。

对于取值较多的类别特征，可以进行一下处理：

- 统计每个取值在样本中出现的频率，取 Top N 的取值进行 One-hot 编码，剩下的类别分到“其他“类目下，其中 N 需要根据模型效果进行调优；
- 统计每个 ID 特征的一些统计量（譬如历史平均点击率，历史平均浏览率）等代替该 ID 取值作为特征。

### ③时间序列特征

很多数据挖掘任务重通常需要对时间相关的数据进行分析，然后对之后某段时间的某个目标值进行预测。对于预测的质量，它依赖于以下一些因素：

- 因素如何影响我们的结果；
- 我们拥有多少数据；
- 我们的预测是否会影响我们预测的结果。



- 滑动窗口时间段内的各个特征的统计特征。


### ④特征选择

## 4、模型选择



## 6、模型集成